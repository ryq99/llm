# LARGE LANGUAGE MODEL
### Transformer Architecture
[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)  
[BLOOM: BigScience 176B Model](https://arxiv.org/pdf/2211.05100.pdf)  

### Pre-training and scaling laws
[Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361.pdf)

### Model architectures and pre-training objectives
[What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?](https://arxiv.org/pdf/2204.05832.pdf)  
[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf) 

### Scaling laws and compute-optimal models
[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
[Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556.pdf)  
[BloombergGPT: A Large Language Model for Finance](https://arxiv.org/pdf/2303.17564.pdf)

### Model Finetuning
[Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)
