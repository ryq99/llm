# LARGE LANGUAGE MODEL
### Transformer Architecture
[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)  
[BLOOM: BigScience 176B Model](https://arxiv.org/pdf/2211.05100.pdf)  

<br>

### Prompting
[Chain-of-thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)  
[PAL: Program-aided Language Models](https://arxiv.org/pdf/2211.10435.pdf)  
[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)

<br>

### Pre-training and scaling laws
[Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361.pdf)

<br>

### Model architectures and pre-training objectives
[What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?](https://arxiv.org/pdf/2204.05832.pdf)  
[LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf) 

<br>

### Scaling laws and compute-optimal models
[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)  
[Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556.pdf)  
[BloombergGPT: A Large Language Model for Finance](https://arxiv.org/pdf/2303.17564.pdf)  

<br>

### Instruction Finetuning
[Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)  
[Introducing FLAN: More generalizable Language Models with Instruction Fine-Tuning](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html)  

<br>

### Parameter-efficient Fine-tuning (PEFT)
[Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2303.15647.pdf)
[On the Effectiveness of Parameter-Efficient Fine-Tuning](https://arxiv.org/pdf/2211.15583.pdf)
#### LoRA  
[LoRA Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)  
[QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314.pdf)  
#### Prompt Tuning  
[The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)  

<br>

### RLHF Fine-tuning
[Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU](https://huggingface.co/blog/trl-peft)  
[Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf)  
[Learning to summarize from human feedback](https://arxiv.org/pdf/2009.01325.pdf)  
[Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347.pdf)  
[Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290.pdf)  
[Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073.pdf)

<br>

### Model Evaluation Metrics
[Holistic Evaluation of Language Model](https://crfm.stanford.edu/helm/latest/?scenarios=1)  
[General Language Understanding Evaluation (GLUE) benchmark](https://openreview.net/pdf?id=rJ4km2R5t7)  
[SuperGLUE](https://super.gluebenchmark.com/)  
[ROUGE: A Package for Automatic Evaluation of Summaries](https://aclanthology.org/W04-1013.pdf)  
[Measuring Massive Multitask Language Understanding (MMLU)](https://arxiv.org/pdf/2009.03300.pdf)  
[BigBench-Hard - Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models](https://arxiv.org/pdf/2206.04615.pdf)  

<br> 

### Application
[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)  
[LangChain](https://github.com/langchain-ai/langchain)
[Who Owns the Generative AI Platform?](https://a16z.com/2023/01/19/who-owns-the-generative-ai-platform/)

